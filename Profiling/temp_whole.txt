5 Input images are read from /data/local/ARM-CO-UP/assets//ppm_images_608/
[UtilsPipeline.h] image directory is: /data/local/ARM-CO-UP/assets//ppm_images_608//
Threads : 2
Small Cores Threads : 4
Target : Neon
Data type : F32
Data layout : NHWC
Tuner enabled? : false
Cache enabled? : false
Tuner mode : Normal
Tuner file : 
MLGO file : 
Fast math enabled? : false
Data path : /data/local/ARM-CO-UP/assets//yolov3/
Image file : /data/local/ARM-CO-UP/assets//ppm_images_608//
Labels file : /data/local/ARM-CO-UP/assets//coco.names
Partition point is : 0
Second partition point is : 0
Order is : GLLLLNNNNNNNNNNLLLLLLLLLNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNLNLLLLLLLLL
freqs of layers : 
power_profile_mode : whole
GPU host is: B
NPU host is: B
Number of totla cores is : 6
Number of little cores is : 4
Number of big cores is : 2
Print task names : 0
Run network for 10 times.
Layer timing: 0

Adding Graph0 target 2 PE: G Host PE: B num threads: 0 Layers: 0-0
Adding Graph1 target 1 PE: L Host PE: L num threads: 4 Layers: 1-4
Adding Graph2 target 4 PE: N Host PE: B num threads: 0 Layers: 5-14
Adding Graph3 target 1 PE: L Host PE: L num threads: 4 Layers: 15-23
Adding Graph4 target 4 PE: N Host PE: B num threads: 0 Layers: 24-63
Adding Graph5 target 1 PE: L Host PE: L num threads: 4 Layers: 64-64
Adding Graph6 target 4 PE: N Host PE: B num threads: 0 Layers: 65-65
Adding Graph7 target 1 PE: L Host PE: L num threads: 4 Layers: 66-74
pandoon
pandoon
pandoon
Pandoon opened at 3
Threads : 2
Small Cores Threads : 4
Target : Neon
Data type : F32
Data layout : NHWC
Tuner enabled? : false
Cache enabled? : false
Tuner mode : Normal
Tuner file : 
MLGO file : 
Fast math enabled? : false
Data path : /data/local/ARM-CO-UP/assets//yolov3/
Image file : /data/local/ARM-CO-UP/assets//ppm_images_608//
Labels file : /data/local/ARM-CO-UP/assets//coco.names
Partition point is : 0
Second partition point is : 0
Order is : GLLLLNNNNNNNNNNLLLLLLLLLNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNLNLLLLLLLLL
freqs of layers : 
power_profile_mode : whole
GPU host is: B
NPU host is: B
Number of totla cores is : 6
Number of little cores is : 4
Number of big cores is : 2
Print task names : 0
Run network for 10 times.
Layer timing: 0

****************************
GraphUtils.cpp- reading images: /data/local/ARM-CO-UP/assets//ppm_images_608//
/data/local/ARM-CO-UP/assets//ppm_images_608//apple.ppm
/data/local/ARM-CO-UP/assets//ppm_images_608//dishes.ppm
/data/local/ARM-CO-UP/assets//ppm_images_608//bus.ppm
/data/local/ARM-CO-UP/assets//ppm_images_608//zebra.ppm
/data/local/ARM-CO-UP/assets//ppm_images_608//bear.ppm
*****************************



-1 skipping layer: 
			0 layer: conv2d_1/Conv2D
			0 skipping layer: conv2d_1/BatchNorm
			0 skipping layer: conv2d_1/LeakyRelu
1 layer: conv2d_2/Conv2D
Input node for the layer 1 is in graph: 0 Adding Transmitter to that graph
Adding Sender_conv2d_1/LeakyRelu to graph 0 with target 2
Adding Receiver_conv2d_1/LeakyRelu to graph 1 with target 1
1 skipping layer: conv2d_2/BatchNorm
1 skipping layer: conv2d_2/LeakyRelu
			2 layer: conv2d_3/Conv2D
			2 skipping layer: conv2d_3/BatchNorm
			2 skipping layer: conv2d_3/LeakyRelu
3 layer: conv2d_4/Conv2D
3 skipping layer: conv2d_4/BatchNorm
3 skipping layer: conv2d_4/LeakyRelu
3 skipping layer: add_3_4
			4 layer: conv2d_5/Conv2D
			4 skipping layer: conv2d_5/BatchNorm
			4 skipping layer: conv2d_5/LeakyRelu
5 layer: conv2d_6/Conv2D
Input node for the layer 5 is in graph: 1 Adding Transmitter to that graph
Adding Sender_conv2d_5/LeakyRelu to graph 1 with target 1
Adding Receiver_conv2d_5/LeakyRelu to graph 2 with target 4
5 skipping layer: conv2d_6/BatchNorm
5 skipping layer: conv2d_6/LeakyRelu
			6 layer: conv2d_7/Conv2D
			6 skipping layer: conv2d_7/BatchNorm
			6 skipping layer: conv2d_7/LeakyRelu
			6 skipping layer: add_6_7
7 layer: conv2d_8/Conv2D
7 skipping layer: conv2d_8/BatchNorm
7 skipping layer: conv2d_8/LeakyRelu
			8 layer: conv2d_9/Conv2D
			8 skipping layer: conv2d_9/BatchNorm
			8 skipping layer: conv2d_9/LeakyRelu
			8 skipping layer: add_8_9
9 layer: conv2d_10/Conv2D
9 skipping layer: conv2d_10/BatchNorm
9 skipping layer: conv2d_10/LeakyRelu
			10 layer: conv2d_11/Conv2D
			10 skipping layer: conv2d_11/BatchNorm
			10 skipping layer: conv2d_11/LeakyRelu
11 layer: conv2d_12/Conv2D
11 skipping layer: conv2d_12/BatchNorm
11 skipping layer: conv2d_12/LeakyRelu
11 skipping layer: add_11_12
			12 layer: conv2d_13/Conv2D
			12 skipping layer: conv2d_13/BatchNorm
			12 skipping layer: conv2d_13/LeakyRelu
13 layer: conv2d_14/Conv2D
13 skipping layer: conv2d_14/BatchNorm
13 skipping layer: conv2d_14/LeakyRelu
13 skipping layer: add_13_14
			14 layer: conv2d_15/Conv2D
			14 skipping layer: conv2d_15/BatchNorm
			14 skipping layer: conv2d_15/LeakyRelu
15 layer: conv2d_16/Conv2D
Input node for the layer 15 is in graph: 2 Adding Transmitter to that graph
Adding Sender_conv2d_15/LeakyRelu to graph 2 with target 4
Adding Receiver_conv2d_15/LeakyRelu to graph 3 with target 1
15 skipping layer: conv2d_16/BatchNorm
15 skipping layer: conv2d_16/LeakyRelu
15 skipping layer: add_15_16
Input node for the layer 15 is in graph: 2 Adding Transmitter to that graph
Adding Sender_add_13_14 to graph 2 with target 4
Adding Receiver_add_13_14 to graph 3 with target 1
			16 layer: conv2d_17/Conv2D
			16 skipping layer: conv2d_17/BatchNorm
			16 skipping layer: conv2d_17/LeakyRelu
17 layer: conv2d_18/Conv2D
17 skipping layer: conv2d_18/BatchNorm
17 skipping layer: conv2d_18/LeakyRelu
17 skipping layer: add_17_18
			18 layer: conv2d_19/Conv2D
			18 skipping layer: conv2d_19/BatchNorm
			18 skipping layer: conv2d_19/LeakyRelu
19 layer: conv2d_20/Conv2D
19 skipping layer: conv2d_20/BatchNorm
19 skipping layer: conv2d_20/LeakyRelu
19 skipping layer: add_19_20
			20 layer: conv2d_21/Conv2D
			20 skipping layer: conv2d_21/BatchNorm
			20 skipping layer: conv2d_21/LeakyRelu
21 layer: conv2d_22/Conv2D
21 skipping layer: conv2d_22/BatchNorm
21 skipping layer: conv2d_22/LeakyRelu
21 skipping layer: add_21_22
			22 layer: conv2d_23/Conv2D
			22 skipping layer: conv2d_23/BatchNorm
			22 skipping layer: conv2d_23/LeakyRelu
23 layer: conv2d_24/Conv2D
23 skipping layer: conv2d_24/BatchNorm
23 skipping layer: conv2d_24/LeakyRelu
23 skipping layer: add_23_24
			24 layer: conv2d_25/Conv2D
Input node for the layer 24 is in graph: 3 Adding Transmitter to that graph
Adding Sender_add_23_24 to graph 3 with target 1
Adding Receiver_add_23_24 to graph 4 with target 4
			24 skipping layer: conv2d_25/BatchNorm
			24 skipping layer: conv2d_25/LeakyRelu
25 layer: conv2d_26/Conv2D
25 skipping layer: conv2d_26/BatchNorm
25 skipping layer: conv2d_26/LeakyRelu
25 skipping layer: add_25_26
			26 layer: conv2d_27/Conv2D
			26 skipping layer: conv2d_27/BatchNorm
			26 skipping layer: conv2d_27/LeakyRelu
27 layer: conv2d_28/Conv2D
27 skipping layer: conv2d_28/BatchNorm
27 skipping layer: conv2d_28/LeakyRelu
			28 layer: conv2d_29/Conv2D
			28 skipping layer: conv2d_29/BatchNorm
			28 skipping layer: conv2d_29/LeakyRelu
			28 skipping layer: add_28_29
29 layer: conv2d_30/Conv2D
29 skipping layer: conv2d_30/BatchNorm
29 skipping layer: conv2d_30/LeakyRelu
			30 layer: conv2d_31/Conv2D
			30 skipping layer: conv2d_31/BatchNorm
			30 skipping layer: conv2d_31/LeakyRelu
			30 skipping layer: add_30_31
31 layer: conv2d_32/Conv2D
31 skipping layer: conv2d_32/BatchNorm
31 skipping layer: conv2d_32/LeakyRelu
			32 layer: conv2d_33/Conv2D
			32 skipping layer: conv2d_33/BatchNorm
			32 skipping layer: conv2d_33/LeakyRelu
			32 skipping layer: add_32_33
33 layer: conv2d_34/Conv2D
33 skipping layer: conv2d_34/BatchNorm
33 skipping layer: conv2d_34/LeakyRelu
			34 layer: conv2d_35/Conv2D
			34 skipping layer: conv2d_35/BatchNorm
			34 skipping layer: conv2d_35/LeakyRelu
			34 skipping layer: add_34_35
35 layer: conv2d_36/Conv2D
35 skipping layer: conv2d_36/BatchNorm
35 skipping layer: conv2d_36/LeakyRelu
			36 layer: conv2d_37/Conv2D
			36 skipping layer: conv2d_37/BatchNorm
			36 skipping layer: conv2d_37/LeakyRelu
			36 skipping layer: add_36_37
37 layer: conv2d_38/Conv2D
37 skipping layer: conv2d_38/BatchNorm
37 skipping layer: conv2d_38/LeakyRelu
			38 layer: conv2d_39/Conv2D
			38 skipping layer: conv2d_39/BatchNorm
			38 skipping layer: conv2d_39/LeakyRelu
			38 skipping layer: add_38_39
39 layer: conv2d_40/Conv2D
39 skipping layer: conv2d_40/BatchNorm
39 skipping layer: conv2d_40/LeakyRelu
			40 layer: conv2d_41/Conv2D
			40 skipping layer: conv2d_41/BatchNorm
			40 skipping layer: conv2d_41/LeakyRelu
			40 skipping layer: add_40_41
41 layer: conv2d_42/Conv2D
41 skipping layer: conv2d_42/BatchNorm
41 skipping layer: conv2d_42/LeakyRelu
			42 layer: conv2d_43/Conv2D
			42 skipping layer: conv2d_43/BatchNorm
			42 skipping layer: conv2d_43/LeakyRelu
			42 skipping layer: add_42_43
43 layer: conv2d_44/Conv2D
43 skipping layer: conv2d_44/BatchNorm
43 skipping layer: conv2d_44/LeakyRelu
			44 layer: conv2d_45/Conv2D
			44 skipping layer: conv2d_45/BatchNorm
			44 skipping layer: conv2d_45/LeakyRelu
45 layer: conv2d_46/Conv2D
45 skipping layer: conv2d_46/BatchNorm
45 skipping layer: conv2d_46/LeakyRelu
45 skipping layer: add_45_46
			46 layer: conv2d_47/Conv2D
			46 skipping layer: conv2d_47/BatchNorm
			46 skipping layer: conv2d_47/LeakyRelu
47 layer: conv2d_48/Conv2D
47 skipping layer: conv2d_48/BatchNorm
47 skipping layer: conv2d_48/LeakyRelu
47 skipping layer: add_47_48
			48 layer: conv2d_49/Conv2D
			48 skipping layer: conv2d_49/BatchNorm
			48 skipping layer: conv2d_49/LeakyRelu
49 layer: conv2d_50/Conv2D
49 skipping layer: conv2d_50/BatchNorm
49 skipping layer: conv2d_50/LeakyRelu
49 skipping layer: add_49_50
			50 layer: conv2d_51/Conv2D
			50 skipping layer: conv2d_51/BatchNorm
			50 skipping layer: conv2d_51/LeakyRelu
51 layer: conv2d_52/Conv2D
51 skipping layer: conv2d_52/BatchNorm
51 skipping layer: conv2d_52/LeakyRelu
51 skipping layer: add_51_52
			52 layer: conv2d_53
			52 skipping layer: conv2d_53/BatchNorm
			52 skipping layer: conv2d_53/LeakyRelu
53 layer: conv2d_54
53 skipping layer: conv2d_54/BatchNorm
53 skipping layer: conv2d_54/LeakyRelu
			54 layer: conv2d_55
			54 skipping layer: conv2d_55/BatchNorm
			54 skipping layer: conv2d_55/LeakyRelu
55 layer: conv2d_56
55 skipping layer: conv2d_56/BatchNorm
55 skipping layer: conv2d_56/LeakyRelu
			56 layer: conv2d_57
			56 skipping layer: conv2d_57/BatchNorm
			56 skipping layer: conv2d_57/LeakyRelu
57 layer: conv2d_58
57 skipping layer: conv2d_58/BatchNorm
57 skipping layer: conv2d_58/LeakyRelu
			58 layer: conv2d_59
			58 skipping layer: conv2d_59/Linear
			58 skipping layer: Yolo1
output accessor reading label file /data/local/ARM-CO-UP/assets//coco.names
			58 skipping layer: output
59 layer: conv2d_60
59 skipping layer: conv2d_59/BatchNorm
59 skipping layer: conv2d_60/LeakyRelu
59 skipping layer: Upsample_60
59 skipping layer: Route1
			60 layer: conv2d_61
			60 skipping layer: conv2d_60/BatchNorm
			60 skipping layer: conv2d_61/LeakyRelu
61 layer: conv2d_62
61 skipping layer: conv2d_61/BatchNorm
61 skipping layer: conv2d_62/LeakyRelu
			62 layer: conv2d_63
			62 skipping layer: conv2d_62/BatchNorm
			62 skipping layer: conv2d_63/LeakyRelu
63 layer: conv2d_64
63 skipping layer: conv2d_63/BatchNorm
63 skipping layer: conv2d_64/LeakyRelu
			64 layer: conv2d_65
Input node for the layer 64 is in graph: 4 Adding Transmitter to that graph
Adding Sender_conv2d_64/LeakyRelu to graph 4 with target 4
Adding Receiver_conv2d_64/LeakyRelu to graph 5 with target 1
			64 skipping layer: conv2d_65/BatchNorm
			64 skipping layer: conv2d_65/LeakyRelu
65 layer: conv2d_66
Input node for the layer 65 is in graph: 5 Adding Transmitter to that graph
Adding Sender_conv2d_65/LeakyRelu to graph 5 with target 1
Adding Receiver_conv2d_65/LeakyRelu to graph 6 with target 4
65 skipping layer: conv2d_65/BatchNorm
65 skipping layer: conv2d_66/LeakyRelu
			66 layer: conv2d_67
Input node for the layer 66 is in graph: 6 Adding Transmitter to that graph
Adding Sender_conv2d_66/LeakyRelu to graph 6 with target 4
Adding Receiver_conv2d_66/LeakyRelu to graph 7 with target 1
			66 skipping layer: conv2d_67/Linear
			66 skipping layer: Yolo2
output accessor reading label file /data/local/ARM-CO-UP/assets//coco.names
			66 skipping layer: output
67 layer: conv2d_68
Input node for the layer 67 is in graph: 5and there is a sender node (mapped) for that node
Adding Receiver_conv2d_65/LeakyRelu to graph 7 with target 1
67 skipping layer: conv2d_66/BatchNorm
67 skipping layer: conv2d_68/LeakyRelu
67 skipping layer: Upsample_68
67 skipping layer: Route2
Input node for the layer 67 is in graph: 4 Adding Transmitter to that graph
Adding Sender_add_25_26 to graph 4 with target 4
Adding Receiver_add_25_26 to graph 7 with target 1
			68 layer: conv2d_69
			68 skipping layer: conv2d_67/BatchNorm
			68 skipping layer: conv2d_69/LeakyRelu
69 layer: conv2d_70
69 skipping layer: conv2d_68/BatchNorm
69 skipping layer: conv2d_70/LeakyRelu
			70 layer: conv2d_71
			70 skipping layer: conv2d_69/BatchNorm
			70 skipping layer: conv2d_71/LeakyRelu
71 layer: conv2d_72
71 skipping layer: conv2d_70/BatchNorm
71 skipping layer: conv2d_72/LeakyRelu
			72 layer: conv2d_73
			72 skipping layer: conv2d_71/BatchNorm
			72 skipping layer: conv2d_73/LeakyRelu
73 layer: conv2d_74
73 skipping layer: conv2d_72/BatchNorm
73 skipping layer: conv2d_74/LeakyRelu
			74 layer: conv2d_75
			74 skipping layer: conv2d_75/Linear
			74 skipping layer: Yolo3
output accessor reading label file /data/local/ARM-CO-UP/assets//coco.names
			74 skipping layer: output
graph 2 target is NPU, merging nodes into one NPU Node ...
Adding NPU Node NPU_YOLOv3_5_14 to graph 2 with target 4
re-struct output node Sender_conv2d_15/LeakyRelu to the npu node
producer is conv2d_15/LeakyRelu
removing edge between producer and the output
adding edge between NPU node and the output
re-struct output node Sender_add_13_14 to the npu node
producer is add_13_14
removing edge between producer and the output
adding edge between NPU node and the output
re-struct input node Receiver_conv2d_5/LeakyRelu with 2out edges to the npu node
consumer is conv2d_6/Conv2D
removing edge between input and the consumer
adding edge between input and NPU node
consumer is add_6_7
removing edge between input and the consumer
adding edge between input and NPU node
npu node created

graph 4 target is NPU, merging nodes into one NPU Node ...
Adding NPU Node NPU_YOLOv3_24_63 to graph 4 with target 4
re-struct output node output to the npu node
producer is Yolo1
removing edge between producer and the output
adding edge between NPU node and the output
re-struct output node Sender_conv2d_64/LeakyRelu to the npu node
producer is conv2d_64/LeakyRelu
removing edge between producer and the output
adding edge between NPU node and the output
re-struct output node Sender_add_25_26 to the npu node
producer is add_25_26
removing edge between producer and the output
adding edge between NPU node and the output
re-struct input node Receiver_add_23_24 with 2out edges to the npu node
consumer is conv2d_25/Conv2D
removing edge between input and the consumer
adding edge between input and NPU node
consumer is add_25_26
removing edge between input and the consumer
adding edge between input and NPU node
npu node created

graph 6 target is NPU, merging nodes into one NPU Node ...
Adding NPU Node NPU_YOLOv3_65_65 to graph 6 with target 4
re-struct output node Sender_conv2d_66/LeakyRelu to the npu node
producer is conv2d_66/LeakyRelu
removing edge between producer and the output
adding edge between NPU node and the output
re-struct input node Receiver_conv2d_65/LeakyRelu with 1out edges to the npu node
consumer is conv2d_66
removing edge between input and the consumer
adding edge between input and NPU node
npu node created



*********************
Start finalizing Graphs
*******************

Graph id: 0 Target is: CL
Graph (0) Task 0: conv2d_1/Conv2D
task has been emplaced
Graph (0) Task 1: conv2d_1/BatchNorm
task has been emplaced
Graph (0) Task 2: conv2d_1/LeakyRelu
task has been emplaced
Graph 0 input size: 1 receiver size: 0 tasks size: 3 senders size: 1 output size: 0

setting ending for layer: conv2d_1/LeakyRelu
Finish finalizing graph 0



Graph id: 1 Target is: Neon
NEDevicebackend num_threads: 4
Worker Thread:: worder thread created with core_pin: -1
Worker Thread:: worder thread created with core_pin: -1



************************
set thread with affinity; cluster 0
_num_threads is: 4
set affinity of main thread to core 0
Worker Thread:: worder thread created with core_pin: 1
Worker Thread:: worder thread created with core_pin: 2
Worker Thread:: worder thread created with core_pin: 3

*******************************

Graph (1) Task 0: conv2d_2/Conv2D
task has been emplaced
Graph (1) Task 1: conv2d_2/BatchNorm
task has been emplaced
Graph (1) Task 2: conv2d_2/LeakyRelu
task has been emplaced
Graph (1) Task 3: conv2d_3/Conv2D
task has been emplaced
Graph (1) Task 4: conv2d_3/BatchNorm
task has been emplaced
Graph (1) Task 5: conv2d_3/LeakyRelu
task has been emplaced
Graph (1) Task 6: conv2d_4/Conv2D
task has been emplaced
Graph (1) Task 7: conv2d_4/BatchNorm
task has been emplaced
Graph (1) Task 8: conv2d_4/LeakyRelu
task has been emplaced
Graph (1) Task 9: add_3_4
task has been emplaced
Graph (1) Task 10: conv2d_5/Conv2D
task has been emplaced
Graph (1) Task 11: conv2d_5/BatchNorm
task has been emplaced
Graph (1) Task 12: conv2d_5/LeakyRelu
task has been emplaced
Graph 1 input size: 0 receiver size: 1 tasks size: 13 senders size: 1 output size: 0

setting ending for layer: conv2d_2/LeakyRelu
setting ending for layer: conv2d_3/LeakyRelu
setting ending for layer: add_3_4
setting ending for layer: conv2d_5/LeakyRelu
Finish finalizing graph 1



Graph id: 2 Target is: NPU
digraph YOLOv3{
n0 [label = "Receiver_conv2d_5/LeakyRelu \n NPU \n "];
n85 [label = "Sender_conv2d_15/LeakyRelu \n NPU \n "];
n86 [label = "Sender_add_13_14 \n NPU \n "];
n87 [label = "NPU_YOLOv3_5_14 \n NPU \n "];
n87 -> n85 [label = "128x76x76 \n F32 \n NHWC"];
n87 -> n86 [label = "256x76x76 \n F32 \n NHWC"];
n0 -> n87 [label = "128x152x152 \n F32 \n NHWC"];
n0 -> n87 [label = "128x152x152 \n F32 \n NHWC"];
}
topological node counts original graph: 4
after topo node NPU_YOLOv3_5_14
after topo node Sender_conv2d_15/LeakyRelu
after topo node Sender_add_13_14
Creating a RockPi NPU node...
NPU YOLOv3_5_14 Number of inputs: 1 and number of outputs: 2
Model name: /data/local/ARM-CO-UP/graphs/YOLOv3_5_14.rknn
NPU /data/local/ARM-CO-UP/graphs/YOLOv3_5_14.rknn Reading model...
NPU /data/local/ARM-CO-UP/graphs/YOLOv3_5_14.rknn Initialized
model input num: 1, output num: 2

Number of NPU model outputs: 2 number of NPU subgraph outputs: 2
Number of NPU model inputs: 1 number of NPU subgraph inputs: 1
NPU Model YOLOv3_5_14 Input:0	Num elements:2957312	Size:2957312	Name:	Fmt:1	Qnt type:2	Type:3
Explre input 0 n_elements: 2957312
Is match with sub graph input: 0

NPU Model YOLOv3_5_14 Output:0	Num elements:1478656	Size:1478656	Name:	Fmt:0	Qnt type:2	Type:3
Explore output 0 n_elements: 739328
Explore output 1 n_elements: 1478656
Is match with sub graph output: 1

NPU Model YOLOv3_5_14 Output:1	Num elements:739328	Size:739328	Name:	Fmt:0	Qnt type:2	Type:3
Explore output 0 n_elements: 739328
Is match with sub graph output: 0
Graph (2) Task 0: NPU_YOLOv3_5_14
task has been emplaced
Graph 2 input size: 0 receiver size: 1 tasks size: 1 senders size: 2 output size: 0


NPU Model YOLOv3_5_14 Output:0	Num elements:1478656	Size:1478656	Name:	Fmt:0	Qnt type:2	Type:3
Explore output 0 n_elements: 739328
Explore output 1 n_elements: 1478656
Is match with sub graph output: 1

NPU Model YOLOv3_5_14 Output:1	Num elements:739328	Size:739328	Name:	Fmt:0	Qnt type:2	Type:3
Explore output 0 n_elements: 739328
Is match with sub graph output: 0
setting ending for layer: NPU_YOLOv3_5_14
Finish finalizing graph 2



Graph id: 3 Target is: Neon
NEDevicebackend num_threads: 4



************************
set thread with affinity; cluster 0
_num_threads is: 4
set affinity of main thread to core 0
Worker Thread:: worder thread created with core_pin: 1
Worker Thread:: worder thread created with core_pin: 2
Worker Thread:: worder thread created with core_pin: 3

*******************************

Graph (3) Task 0: conv2d_16/Conv2D
task has been emplaced
Graph (3) Task 1: conv2d_16/BatchNorm
task has been emplaced
Graph (3) Task 2: conv2d_16/LeakyRelu
task has been emplaced
Graph (3) Task 3: add_15_16
task has been emplaced
Graph (3) Task 4: conv2d_17/Conv2D
task has been emplaced
Graph (3) Task 5: conv2d_17/BatchNorm
task has been emplaced
Graph (3) Task 6: conv2d_17/LeakyRelu
task has been emplaced
Graph (3) Task 7: conv2d_18/Conv2D
task has been emplaced
Graph (3) Task 8: conv2d_18/BatchNorm
task has been emplaced
Graph (3) Task 9: conv2d_18/LeakyRelu
task has been emplaced
Graph (3) Task 10: add_17_18
task has been emplaced
Graph (3) Task 11: conv2d_19/Conv2D
task has been emplaced
Graph (3) Task 12: conv2d_19/BatchNorm
task has been emplaced
Graph (3) Task 13: conv2d_19/LeakyRelu
task has been emplaced
Graph (3) Task 14: conv2d_20/Conv2D
task has been emplaced
Graph (3) Task 15: conv2d_20/BatchNorm
task has been emplaced
Graph (3) Task 16: conv2d_20/LeakyRelu
task has been emplaced
Graph (3) Task 17: add_19_20
task has been emplaced
Graph (3) Task 18: conv2d_21/Conv2D
task has been emplaced
Graph (3) Task 19: conv2d_21/BatchNorm
task has been emplaced
Graph (3) Task 20: conv2d_21/LeakyRelu
task has been emplaced
Graph (3) Task 21: conv2d_22/Conv2D
task has been emplaced
Graph (3) Task 22: conv2d_22/BatchNorm
task has been emplaced
Graph (3) Task 23: conv2d_22/LeakyRelu
task has been emplaced
Graph (3) Task 24: add_21_22
task has been emplaced
Graph (3) Task 25: conv2d_23/Conv2D
task has been emplaced
Graph (3) Task 26: conv2d_23/BatchNorm
task has been emplaced
Graph (3) Task 27: conv2d_23/LeakyRelu
task has been emplaced
Graph (3) Task 28: conv2d_24/Conv2D
task has been emplaced
Graph (3) Task 29: conv2d_24/BatchNorm
task has been emplaced
Graph (3) Task 30: conv2d_24/LeakyRelu
task has been emplaced
Graph (3) Task 31: add_23_24
task has been emplaced
Graph 3 input size: 0 receiver size: 2 tasks size: 32 senders size: 1 output size: 0

setting ending for layer: add_15_16
setting ending for layer: conv2d_17/LeakyRelu
setting ending for layer: add_17_18
setting ending for layer: conv2d_19/LeakyRelu
setting ending for layer: add_19_20
setting ending for layer: conv2d_21/LeakyRelu
setting ending for layer: add_21_22
setting ending for layer: conv2d_23/LeakyRelu
setting ending for layer: add_23_24
Finish finalizing graph 3



Graph id: 4 Target is: NPU
topological node counts original graph: 5
after topo node NPU_YOLOv3_24_63
after topo node output
after topo node Sender_conv2d_64/LeakyRelu
after topo node Sender_add_25_26
Creating a RockPi NPU node...
NPU YOLOv3_24_63 Number of inputs: 1 and number of outputs: 3
Model name: /data/local/ARM-CO-UP/graphs/YOLOv3_24_63.rknn
NPU /data/local/ARM-CO-UP/graphs/YOLOv3_24_63.rknn Reading model...
NPU /data/local/ARM-CO-UP/graphs/YOLOv3_24_63.rknn Initialized
model input num: 1, output num: 3

Number of NPU model outputs: 3 number of NPU subgraph outputs: 3
Number of NPU model inputs: 1 number of NPU subgraph inputs: 1
NPU Model YOLOv3_24_63 Input:0	Num elements:1478656	Size:1478656	Name:	Fmt:1	Qnt type:2	Type:3
Explre input 0 n_elements: 1478656
Is match with sub graph input: 0

NPU Model YOLOv3_24_63 Output:0	Num elements:1478656	Size:1478656	Name:	Fmt:0	Qnt type:2	Type:3
Explore output 0 n_elements: 92055
Explore output 1 n_elements: 739328
Explore output 2 n_elements: 1478656
Is match with sub graph output: 2

NPU Model YOLOv3_24_63 Output:1	Num elements:739328	Size:739328	Name:	Fmt:0	Qnt type:2	Type:3
Explore output 0 n_elements: 92055
Explore output 1 n_elements: 739328
Is match with sub graph output: 1

NPU Model YOLOv3_24_63 Output:2	Num elements:92055	Size:92055	Name:	Fmt:0	Qnt type:2	Type:3
Explore output 0 n_elements: 92055
Is match with sub graph output: 0
Graph (4) Task 0: NPU_YOLOv3_24_63
task has been emplaced
Graph 4 input size: 0 receiver size: 1 tasks size: 1 senders size: 2 output size: 1


NPU Model YOLOv3_24_63 Output:0	Num elements:1478656	Size:1478656	Name:	Fmt:0	Qnt type:2	Type:3
Explore output 0 n_elements: 92055
Explore output 1 n_elements: 739328
Explore output 2 n_elements: 1478656
Is match with sub graph output: 2

NPU Model YOLOv3_24_63 Output:1	Num elements:739328	Size:739328	Name:	Fmt:0	Qnt type:2	Type:3
Explore output 0 n_elements: 92055
Explore output 1 n_elements: 739328
Is match with sub graph output: 1

NPU Model YOLOv3_24_63 Output:2	Num elements:92055	Size:92055	Name:	Fmt:0	Qnt type:2	Type:3
Explore output 0 n_elements: 92055
Is match with sub graph output: 0
setting ending for layer: NPU_YOLOv3_24_63
Finish finalizing graph 4



Graph id: 5 Target is: Neon
NEDevicebackend num_threads: 4



************************
set thread with affinity; cluster 0
_num_threads is: 4
set affinity of main thread to core 0
Worker Thread:: worder thread created with core_pin: 1
Worker Thread:: worder thread created with core_pin: 2
Worker Thread:: worder thread created with core_pin: 3

*******************************

Graph (5) Task 0: conv2d_65
task has been emplaced
Graph (5) Task 1: conv2d_65/BatchNorm
task has been emplaced
Graph (5) Task 2: conv2d_65/LeakyRelu
task has been emplaced
Graph 5 input size: 0 receiver size: 1 tasks size: 3 senders size: 1 output size: 0

setting ending for layer: conv2d_65/LeakyRelu
Finish finalizing graph 5



Graph id: 6 Target is: NPU
topological node counts original graph: 3
after topo node NPU_YOLOv3_65_65
after topo node Sender_conv2d_66/LeakyRelu
Creating a RockPi NPU node...
NPU YOLOv3_65_65 Number of inputs: 1 and number of outputs: 1
Model name: /data/local/ARM-CO-UP/graphs/YOLOv3_65_65.rknn
NPU /data/local/ARM-CO-UP/graphs/YOLOv3_65_65.rknn Reading model...
model input num: 1, output num: 1
NPU /data/local/ARM-CO-UP/graphs/YOLOv3_65_65.rknn Initialized

Number of NPU model outputs: 1 number of NPU subgraph outputs: 1
Number of NPU model inputs: 1 number of NPU subgraph inputs: 1
NPU Model YOLOv3_65_65 Input:0	Num elements:369664	Size:369664	Name:	Fmt:1	Qnt type:2	Type:3
Explre input 0 n_elements: 369664
Is match with sub graph input: 0

NPU Model YOLOv3_65_65 Output:0	Num elements:739328	Size:739328	Name:	Fmt:0	Qnt type:2	Type:3
Explore output 0 n_elements: 739328
Is match with sub graph output: 0
Graph (6) Task 0: NPU_YOLOv3_65_65
task has been emplaced
Graph 6 input size: 0 receiver size: 1 tasks size: 1 senders size: 1 output size: 0


NPU Model YOLOv3_65_65 Output:0	Num elements:739328	Size:739328	Name:	Fmt:0	Qnt type:2	Type:3
Explore output 0 n_elements: 739328
Is match with sub graph output: 0
setting ending for layer: NPU_YOLOv3_65_65
Finish finalizing graph 6



Graph id: 7 Target is: Neon
NEDevicebackend num_threads: 4



************************
set thread with affinity; cluster 0
_num_threads is: 4
set affinity of main thread to core 0
Worker Thread:: worder thread created with core_pin: 1
Worker Thread:: worder thread created with core_pin: 2
Worker Thread:: worder thread created with core_pin: 3

*******************************

Graph (7) Task 0: conv2d_68
task has been emplaced
Graph (7) Task 1: conv2d_66/BatchNorm
task has been emplaced
Graph (7) Task 2: conv2d_68/LeakyRelu
task has been emplaced
Graph (7) Task 3: Upsample_68
task has been emplaced
Graph (7) Task 4: Route2
task has been emplaced
Graph (7) Task 5: conv2d_69
task has been emplaced
Graph (7) Task 6: conv2d_67/BatchNorm
task has been emplaced
Graph (7) Task 7: conv2d_69/LeakyRelu
task has been emplaced
Graph (7) Task 8: conv2d_70
task has been emplaced
Graph (7) Task 9: conv2d_68/BatchNorm
task has been emplaced
Graph (7) Task 10: conv2d_70/LeakyRelu
task has been emplaced
Graph (7) Task 11: conv2d_71
task has been emplaced
Graph (7) Task 12: conv2d_69/BatchNorm
task has been emplaced
Graph (7) Task 13: conv2d_71/LeakyRelu
task has been emplaced
Graph (7) Task 14: conv2d_72
task has been emplaced
Graph (7) Task 15: conv2d_70/BatchNorm
task has been emplaced
Graph (7) Task 16: conv2d_72/LeakyRelu
task has been emplaced
Graph (7) Task 17: conv2d_73
task has been emplaced
Graph (7) Task 18: conv2d_71/BatchNorm
task has been emplaced
Graph (7) Task 19: conv2d_73/LeakyRelu
task has been emplaced
Graph (7) Task 20: conv2d_74
task has been emplaced
Graph (7) Task 21: conv2d_72/BatchNorm
task has been emplaced
Graph (7) Task 22: conv2d_74/LeakyRelu
task has been emplaced
Graph (7) Task 23: conv2d_75
task has been emplaced
Graph (7) Task 24: conv2d_75/Linear
task has been emplaced
Graph (7) Task 25: Yolo3
task has been emplaced
Graph (7) Task 26: Yolo3
task has been emplaced
Graph (7) Task 27: Yolo3
task has been emplaced
Graph (7) Task 28: Yolo3
task has been emplaced
Graph (7) Task 29: Yolo3
task has been emplaced
Graph (7) Task 30: Yolo3
task has been emplaced
Graph (7) Task 31: conv2d_67
task has been emplaced
Graph (7) Task 32: conv2d_67/Linear
task has been emplaced
Graph (7) Task 33: Yolo2
task has been emplaced
Graph (7) Task 34: Yolo2
task has been emplaced
Graph (7) Task 35: Yolo2
task has been emplaced
Graph (7) Task 36: Yolo2
task has been emplaced
Graph (7) Task 37: Yolo2
task has been emplaced
Graph (7) Task 38: Yolo2
task has been emplaced
Graph 7 input size: 0 receiver size: 3 tasks size: 39 senders size: 0 output size: 2

setting ending for layer: Route2
setting ending for layer: conv2d_69/LeakyRelu
setting ending for layer: conv2d_70/LeakyRelu
setting ending for layer: conv2d_71/LeakyRelu
setting ending for layer: conv2d_72/LeakyRelu
setting ending for layer: conv2d_73/LeakyRelu
setting ending for layer: conv2d_74/LeakyRelu
setting ending for layer: Yolo3
setting ending for layer: Yolo2
Finish finalizing graph 7



setup finished

Please Enter the desired Frequency setttings: 
0 Running Graph with [4,7]-5-5-4-5-7-7-7-7-7-7-7-7-7-7-5-5-4-5-5-5-5-5-5-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-7-4-7-0-4-5-4-5-5-5-4-5 LW DVFS
change governor to false for task:NPU_YOLOv3_65_65
change governor to false for task:Yolo2
change governor to false for task:Yolo2
change governor to false for task:Yolo2
change governor to false for task:Yolo2
change governor to false for task:Yolo2
change governor to false for task:Yolo2
27

0 gov task: conv2d_1/LeakyRelu
1 gov task: conv2d_2/LeakyRelu
2 gov task: conv2d_3/LeakyRelu
3 gov task: add_3_4
4 gov task: conv2d_5/LeakyRelu
5 gov task: NPU_YOLOv3_5_14
6 gov task: add_15_16
7 gov task: conv2d_17/LeakyRelu
8 gov task: add_17_18
9 gov task: conv2d_19/LeakyRelu
10 gov task: add_19_20
11 gov task: conv2d_21/LeakyRelu
12 gov task: add_21_22
13 gov task: conv2d_23/LeakyRelu
14 gov task: add_23_24
15 gov task: NPU_YOLOv3_24_63
16 gov task: conv2d_65/LeakyRelu
17 gov task: NPU_YOLOv3_65_65
18 gov task: Route2
19 gov task: conv2d_69/LeakyRelu
20 gov task: conv2d_70/LeakyRelu
21 gov task: conv2d_71/LeakyRelu
22 gov task: conv2d_72/LeakyRelu
23 gov task: conv2d_73/LeakyRelu
24 gov task: conv2d_74/LeakyRelu
25 gov task: Yolo3
26 gov task: Yolo2
** i:74 governor index:26 Yolo2

** i:0 governor index:0 conv2d_1/LeakyRelu

** i:1 governor index:1 conv2d_2/LeakyRelu

** i:2 governor index:2 conv2d_3/LeakyRelu

** i:3 governor index:3 add_3_4

** i:4 governor index:4 conv2d_5/LeakyRelu
set freq skipping layer 5 which is mapped on NPU
set freq skipping layer 6 which is mapped on NPU
set freq skipping layer 7 which is mapped on NPU
set freq skipping layer 8 which is mapped on NPU
set freq skipping layer 9 which is mapped on NPU
set freq skipping layer 10 which is mapped on NPU
set freq skipping layer 11 which is mapped on NPU
set freq skipping layer 12 which is mapped on NPU
set freq skipping layer 13 which is mapped on NPU

** i:14 governor index:5 NPU_YOLOv3_5_14

** i:15 governor index:6 add_15_16

** i:16 governor index:7 conv2d_17/LeakyRelu

** i:17 governor index:8 add_17_18

** i:18 governor index:9 conv2d_19/LeakyRelu

** i:19 governor index:10 add_19_20

** i:20 governor index:11 conv2d_21/LeakyRelu

** i:21 governor index:12 add_21_22

** i:22 governor index:13 conv2d_23/LeakyRelu

** i:23 governor index:14 add_23_24
set freq skipping layer 24 which is mapped on NPU
set freq skipping layer 25 which is mapped on NPU
set freq skipping layer 26 which is mapped on NPU
set freq skipping layer 27 which is mapped on NPU
set freq skipping layer 28 which is mapped on NPU
set freq skipping layer 29 which is mapped on NPU
set freq skipping layer 30 which is mapped on NPU
set freq skipping layer 31 which is mapped on NPU
set freq skipping layer 32 which is mapped on NPU
set freq skipping layer 33 which is mapped on NPU
set freq skipping layer 34 which is mapped on NPU
set freq skipping layer 35 which is mapped on NPU
set freq skipping layer 36 which is mapped on NPU
set freq skipping layer 37 which is mapped on NPU
set freq skipping layer 38 which is mapped on NPU
set freq skipping layer 39 which is mapped on NPU
set freq skipping layer 40 which is mapped on NPU
set freq skipping layer 41 which is mapped on NPU
set freq skipping layer 42 which is mapped on NPU
set freq skipping layer 43 which is mapped on NPU
set freq skipping layer 44 which is mapped on NPU
set freq skipping layer 45 which is mapped on NPU
set freq skipping layer 46 which is mapped on NPU
set freq skipping layer 47 which is mapped on NPU
set freq skipping layer 48 which is mapped on NPU
set freq skipping layer 49 which is mapped on NPU
set freq skipping layer 50 which is mapped on NPU
set freq skipping layer 51 which is mapped on NPU
set freq skipping layer 52 which is mapped on NPU
set freq skipping layer 53 which is mapped on NPU
set freq skipping layer 54 which is mapped on NPU
set freq skipping layer 55 which is mapped on NPU
set freq skipping layer 56 which is mapped on NPU
set freq skipping layer 57 which is mapped on NPU
set freq skipping layer 58 which is mapped on NPU
set freq skipping layer 59 which is mapped on NPU
set freq skipping layer 60 which is mapped on NPU
set freq skipping layer 61 which is mapped on NPU
set freq skipping layer 62 which is mapped on NPU

** i:63 governor index:15 NPU_YOLOv3_24_63

** i:64 governor index:16 conv2d_65/LeakyRelu

** i:65 governor index:17 NPU_YOLOv3_65_65

** i:66 governor index:18 Route2

** i:67 governor index:19 conv2d_69/LeakyRelu

** i:68 governor index:20 conv2d_70/LeakyRelu

** i:69 governor index:21 conv2d_71/LeakyRelu

** i:70 governor index:22 conv2d_72/LeakyRelu

** i:71 governor index:23 conv2d_73/LeakyRelu

** i:72 governor index:24 conv2d_74/LeakyRelu

** i:73 governor index:25 Yolo3
governor 0 task:NPU_YOLOv3_24_63 freqs:4,0,0
governor 1 task:NPU_YOLOv3_5_14 freqs:5,0,0
governor 2 task:NPU_YOLOv3_65_65 freqs:0,0,0
governor 3 task:Route2 freqs:4,0,0
governor 4 task:Yolo2 freqs:0,7,4
governor 5 task:Yolo3 freqs:5,0,0
governor 6 task:add_15_16 freqs:5,0,0
governor 7 task:add_17_18 freqs:5,0,0
governor 8 task:add_19_20 freqs:5,0,0
governor 9 task:add_21_22 freqs:5,0,0
governor 10 task:add_23_24 freqs:0,7,0
governor 11 task:add_3_4 freqs:5,0,0
governor 12 task:conv2d_1/LeakyRelu freqs:5,0,0
governor 13 task:conv2d_17/LeakyRelu freqs:4,0,0
governor 14 task:conv2d_19/LeakyRelu freqs:5,0,0
governor 15 task:conv2d_2/LeakyRelu freqs:5,0,0
governor 16 task:conv2d_21/LeakyRelu freqs:5,0,0
governor 17 task:conv2d_23/LeakyRelu freqs:5,0,0
governor 18 task:conv2d_3/LeakyRelu freqs:4,0,0
governor 19 task:conv2d_5/LeakyRelu freqs:0,7,0
governor 20 task:conv2d_65/LeakyRelu freqs:0,7,0
governor 21 task:conv2d_69/LeakyRelu freqs:5,0,0
governor 22 task:conv2d_70/LeakyRelu freqs:4,0,0
governor 23 task:conv2d_71/LeakyRelu freqs:5,0,0
governor 24 task:conv2d_72/LeakyRelu freqs:5,0,0
governor 25 task:conv2d_73/LeakyRelu freqs:5,0,0
governor 26 task:conv2d_74/LeakyRelu freqs:4,0,0
0---- conv2d_1/LeakyRelu    processor:G
setting freq of governor task conv2d_1/LeakyRelu
1---- conv2d_2/LeakyRelu    processor:L
setting freq of governor task conv2d_2/LeakyRelu
1---- conv2d_3/LeakyRelu    processor:L
setting freq of governor task conv2d_3/LeakyRelu
1---- add_3_4    processor:L
setting freq of governor task add_3_4
1---- conv2d_5/LeakyRelu    processor:L
setting freq of governor task conv2d_5/LeakyRelu
2---- NPU_YOLOv3_5_14    processor:N
setting freq of governor task NPU_YOLOv3_5_14
3---- add_15_16    processor:L
setting freq of governor task add_15_16
3---- conv2d_17/LeakyRelu    processor:L
setting freq of governor task conv2d_17/LeakyRelu
3---- add_17_18    processor:L
setting freq of governor task add_17_18
3---- conv2d_19/LeakyRelu    processor:L
setting freq of governor task conv2d_19/LeakyRelu
3---- add_19_20    processor:L
setting freq of governor task add_19_20
3---- conv2d_21/LeakyRelu    processor:L
setting freq of governor task conv2d_21/LeakyRelu
3---- add_21_22    processor:L
setting freq of governor task add_21_22
3---- conv2d_23/LeakyRelu    processor:L
setting freq of governor task conv2d_23/LeakyRelu
3---- add_23_24    processor:L
setting freq of governor task add_23_24
4---- NPU_YOLOv3_24_63    processor:N
setting freq of governor task NPU_YOLOv3_24_63
5---- conv2d_65/LeakyRelu    processor:L
setting freq of governor task conv2d_65/LeakyRelu
6---- NPU_YOLOv3_65_65    processor:N
7---- Route2    processor:L
setting freq of governor task Route2
7---- conv2d_69/LeakyRelu    processor:L
setting freq of governor task conv2d_69/LeakyRelu
7---- conv2d_70/LeakyRelu    processor:L
setting freq of governor task conv2d_70/LeakyRelu
7---- conv2d_71/LeakyRelu    processor:L
setting freq of governor task conv2d_71/LeakyRelu
7---- conv2d_72/LeakyRelu    processor:L
setting freq of governor task conv2d_72/LeakyRelu
7---- conv2d_73/LeakyRelu    processor:L
setting freq of governor task conv2d_73/LeakyRelu
7---- conv2d_74/LeakyRelu    processor:L
setting freq of governor task conv2d_74/LeakyRelu
7---- Yolo3    processor:L
setting freq of governor task Yolo3
7---- Yolo2    processor:L
set_GPIOs with mode: whole
set ending of GPIO for task Yolo2
0 task name: conv2d_1/Conv2D	starting gpio: 1	ending gpio: 0	profiling layers: 0	profiling transfers: 0
1 task name: conv2d_1/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
2 task name: conv2d_1/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
3 task name: conv2d_2/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
4 task name: conv2d_2/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
5 task name: conv2d_2/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
6 task name: conv2d_3/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
7 task name: conv2d_3/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
8 task name: conv2d_3/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
9 task name: conv2d_4/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
10 task name: conv2d_4/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
11 task name: conv2d_4/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
12 task name: add_3_4	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
13 task name: conv2d_5/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
14 task name: conv2d_5/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
15 task name: conv2d_5/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
16 task name: NPU_YOLOv3_5_14	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
17 task name: conv2d_16/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
18 task name: conv2d_16/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
19 task name: conv2d_16/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
20 task name: add_15_16	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
21 task name: conv2d_17/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
22 task name: conv2d_17/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
23 task name: conv2d_17/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
24 task name: conv2d_18/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
25 task name: conv2d_18/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
26 task name: conv2d_18/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
27 task name: add_17_18	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
28 task name: conv2d_19/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
29 task name: conv2d_19/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
30 task name: conv2d_19/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
31 task name: conv2d_20/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
32 task name: conv2d_20/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
33 task name: conv2d_20/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
34 task name: add_19_20	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
35 task name: conv2d_21/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
36 task name: conv2d_21/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
37 task name: conv2d_21/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
38 task name: conv2d_22/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
39 task name: conv2d_22/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
40 task name: conv2d_22/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
41 task name: add_21_22	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
42 task name: conv2d_23/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
43 task name: conv2d_23/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
44 task name: conv2d_23/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
45 task name: conv2d_24/Conv2D	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
46 task name: conv2d_24/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
47 task name: conv2d_24/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
48 task name: add_23_24	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
49 task name: NPU_YOLOv3_24_63	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
50 task name: conv2d_65	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
51 task name: conv2d_65/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
52 task name: conv2d_65/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
53 task name: NPU_YOLOv3_65_65	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
54 task name: conv2d_68	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
55 task name: conv2d_66/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
56 task name: conv2d_68/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
57 task name: Upsample_68	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
58 task name: Route2	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
59 task name: conv2d_69	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
60 task name: conv2d_67/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
61 task name: conv2d_69/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
62 task name: conv2d_70	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
63 task name: conv2d_68/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
64 task name: conv2d_70/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
65 task name: conv2d_71	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
66 task name: conv2d_69/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
67 task name: conv2d_71/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
68 task name: conv2d_72	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
69 task name: conv2d_70/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
70 task name: conv2d_72/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
71 task name: conv2d_73	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
72 task name: conv2d_71/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
73 task name: conv2d_73/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
74 task name: conv2d_74	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
75 task name: conv2d_72/BatchNorm	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
76 task name: conv2d_74/LeakyRelu	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
77 task name: conv2d_75	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
78 task name: conv2d_75/Linear	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
79 task name: Yolo3	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
80 task name: Yolo3	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
81 task name: Yolo3	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
82 task name: Yolo3	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
83 task name: Yolo3	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
84 task name: Yolo3	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
85 task name: conv2d_67	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
86 task name: conv2d_67/Linear	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
87 task name: Yolo2	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
88 task name: Yolo2	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
89 task name: Yolo2	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
90 task name: Yolo2	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
91 task name: Yolo2	starting gpio: 0	ending gpio: 0	profiling layers: 0	profiling transfers: 0
92 task name: Yolo2	starting gpio: 0	ending gpio: 1	profiling layers: 0	profiling transfers: 0



*********************************************
start running graphs
*************************************************




************
Photo_index:0	Frame Index:0
Reading image: /data/local/ARM-CO-UP/assets//ppm_images_608//apple.ppm
*************


Segmentation fault 
